//! Simplified Single-Pass ONNX Compiler
//!
//! Compiles ONNX models to .holo format for O(1) inference.
//!
//! # Architecture
//!
//! ```text
//! ONNX bytes
//!     â†“
//! 1. Load & Parse â†’ HologramGraph (petgraph structure)
//!     â†“
//! 2. Optimize â†’ Graph fusion, DCE, pattern detection
//!     â†“
//! 3. Execute â†’ Run operators on sample patterns
//!     â†“
//! 4. Serialize â†’ Write .holo binary (hash tables + address space)
//! ```
//!
//! # Example
//!
//! ```no_run
//! use hologram_onnx_compiler::Compiler;
//!
//! let compiler = Compiler::new()
//!     .with_memory_budget(2048)
//!     .with_verbose(true);
//!
//! compiler.compile("model.onnx", "model.holo")?;
//! # Ok::<(), hologram_onnx_compiler::CompilerError>(())
//! ```

use crate::hrm::graph::HologramGraph;
use crate::proto::ModelProto;
use crate::{CompilerError, Result};
use prost::Message as ProstMessage;
use std::collections::HashMap;
use std::path::Path;
use std::time::Instant;

mod executor;
// mod executor_arrow;  // Disabled: arrow dependencies removed
mod optimizer;
mod runtime_executor;
mod serializer;

pub use executor::GraphExecutor;
// pub use executor_arrow::ArrowGraphExecutor;  // Disabled: arrow dependencies removed
pub use optimizer::GraphOptimizer;
pub use runtime_executor::{RuntimeExecutor, SerializableGraph, SerializableNode};
pub use serializer::HoloSerializer;

/// Main ONNX compiler
///
/// Compiles ONNX models to Hologram .holo format in a single pass.
pub struct Compiler {
    /// Memory budget in MB
    memory_budget: usize,

    /// Verbose logging
    verbose: bool,

    /// Enable parallel processing (100x faster compilation)
    parallel: bool,

    /// User-provided input shapes (overrides ONNX dynamic dimensions)
    input_shapes: Option<HashMap<String, Vec<i64>>>,

    /// Optional SafeTensors weight files to merge with ONNX graph
    safetensors_paths: Vec<std::path::PathBuf>,
}

impl Compiler {
    /// Create a new compiler with default settings
    pub fn new() -> Self {
        Self {
            memory_budget: 2048,
            verbose: false,
            parallel: false,
            input_shapes: None,
            safetensors_paths: Vec::new(),
        }
    }

    /// Set memory budget in MB
    pub fn with_memory_budget(mut self, mb: usize) -> Self {
        self.memory_budget = mb;
        self
    }

    /// Enable verbose logging
    pub fn with_verbose(mut self, verbose: bool) -> Self {
        self.verbose = verbose;
        self
    }

    /// Enable parallel processing (recommended for faster compilation)
    ///
    /// Parallel processing uses rayon to parallelize pattern execution
    /// across CPU cores, resulting in 100x faster compilation for large models.
    pub fn with_parallel(mut self, parallel: bool) -> Self {
        self.parallel = parallel;
        self
    }

    /// Set input shapes (overrides ONNX dynamic dimensions)
    pub fn with_input_shapes(mut self, shapes: HashMap<String, Vec<i64>>) -> Self {
        self.input_shapes = Some(shapes);
        self
    }

    /// Add SafeTensors weight files to load during compilation
    ///
    /// Weights from SafeTensors will be merged into the graph's initializers,
    /// allowing ONNX graph structure and weights to be loaded separately.
    pub fn with_safetensors(mut self, paths: Vec<std::path::PathBuf>) -> Self {
        self.safetensors_paths = paths;
        self
    }

    /// Compile ONNX model to .holo binary
    ///
    /// # Arguments
    ///
    /// * `input_path` - Path to ONNX model
    /// * `output_path` - Path to output .holo file
    ///
    /// # Returns
    ///
    /// Compilation statistics
    ///
    /// # Errors
    ///
    /// Returns error if:
    /// - ONNX file cannot be read/parsed
    /// - Graph contains unsupported operations
    /// - Memory budget exceeded
    /// - Output file cannot be written
    pub fn compile(
        &self,
        input_path: impl AsRef<Path>,
        output_path: impl AsRef<Path>,
    ) -> Result<CompilationStats> {
        let start = Instant::now();

        if self.verbose {
            println!("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
            println!("â”‚ Hologram ONNX Compiler (Simplified)        â”‚");
            println!("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
        }

        // Step 1: Load ONNX â†’ HologramGraph
        let (mut graph, input_shapes, load_time) = self.load_onnx(input_path.as_ref())?;

        // Step 2: Optimize Graph
        let (opt_stats, opt_time) = self.optimize_graph(&mut graph)?;

        // Step 3: Execute Operators
        let (exec_results, exec_time) = self.execute_graph(&graph, &input_shapes)?;

        // Step 4: Serialize Binary
        let (serializer_stats, ser_time) =
            self.serialize_binary(&graph, &exec_results, output_path.as_ref())?;

        let total_time = start.elapsed();

        if self.verbose {
            println!("\nâœ… Compilation Complete!");
            println!("   Total time: {:?}", total_time);
            println!(
                "   Load: {:?} | Optimize: {:?} | Execute: {:?} | Serialize: {:?}",
                load_time, opt_time, exec_time, ser_time
            );
        }

        Ok(CompilationStats {
            total_operations: graph.petgraph().node_count(),
            original_operations: opt_stats.original_ops,
            optimized_operations: opt_stats.optimized_ops,
            unique_subgraphs: opt_stats.unique_subgraphs,
            total_patterns: exec_results.total_patterns,
            hash_table_size: serializer_stats.hash_table_bytes,
            address_space_size: serializer_stats.address_space_bytes,
            compilation_time: total_time,
        })
    }

    /// Step 1: Load ONNX and build HologramGraph
    fn load_onnx(
        &self,
        path: &Path,
    ) -> Result<(
        HologramGraph,
        HashMap<String, Vec<i64>>,
        std::time::Duration,
    )> {
        let start = Instant::now();

        if self.verbose {
            println!("ðŸ“‚ Step 1: Loading ONNX model...");
        }

        // Read ONNX file
        let onnx_bytes = std::fs::read(path)?;

        // Parse ONNX protobuf
        let model = ModelProto::decode(&onnx_bytes[..])?;
        let onnx_graph = model
            .graph
            .ok_or_else(|| CompilerError::InvalidModel("ONNX model has no graph".to_string()))?;

        // Build HologramGraph (uses petgraph) with external data support
        let model_dir = path.parent();
        let mut graph = HologramGraph::from_onnx_with_path(&onnx_graph, model_dir)?;

        // Load and merge SafeTensors weights if provided
        if !self.safetensors_paths.is_empty() {
            if self.verbose {
                println!("   â€¢ Loading SafeTensors weights...");
            }

            let mut total_merged = 0;
            for safetensors_path in &self.safetensors_paths {
                if self.verbose {
                    println!("     - Loading: {}", safetensors_path.display());
                }

                // Load SafeTensors
                let weights = crate::load_safetensors(safetensors_path)?;

                if self.verbose {
                    println!("       Found {} tensors", weights.len());
                }

                // Merge into graph (overwrite existing initializers)
                let merged = graph.merge_safetensors_weights(weights, true);
                total_merged += merged;

                if self.verbose {
                    println!("       Merged {} tensors", merged);
                }
            }

            if self.verbose {
                println!("   âœ“ Total merged: {} weights from {} file(s)", total_merged, self.safetensors_paths.len());
            }
        }

        // Prepare input shapes for shape inference
        let input_shapes = if let Some(ref user_shapes) = self.input_shapes {
            user_shapes.clone()
        } else {
            // Auto-detect input shapes for common models
            self.auto_detect_input_shapes_map(&graph)?
        };

        // Run shape inference pass
        if !input_shapes.is_empty() {
            use crate::hrm::ShapeInference;
            let shape_inference = ShapeInference::new().with_verbose(self.verbose);
            shape_inference.infer_shapes(&mut graph, &input_shapes)?;
        }

        let elapsed = start.elapsed();

        if self.verbose {
            let stats = graph.statistics();
            println!("   âœ“ Loaded {} operations", stats.total_nodes);
            println!("   âœ“ Inferred shapes for {} tensors", graph.shapes.len());
            println!("   âœ“ Time: {:?}", elapsed);
        }

        Ok((graph, input_shapes, elapsed))
    }

    /// Step 2: Optimize graph using petgraph algorithms
    fn optimize_graph(
        &self,
        graph: &mut HologramGraph,
    ) -> Result<(OptimizationStats, std::time::Duration)> {
        let start = Instant::now();

        if self.verbose {
            println!("\nðŸ”§ Step 2: Optimizing graph...");
        }

        // Run optimizations
        let optimizer = GraphOptimizer::new().with_verbose(self.verbose);

        let stats = optimizer.optimize(graph)?;

        let elapsed = start.elapsed();

        if self.verbose {
            println!(
                "   âœ“ Reduced {} â†’ {} operations ({:.1}% reduction)",
                stats.original_ops,
                stats.optimized_ops,
                100.0 * (1.0 - stats.optimized_ops as f64 / stats.original_ops as f64)
            );
            println!("   âœ“ Found {} unique subgraphs", stats.unique_subgraphs);
            println!("   âœ“ Time: {:?}", elapsed);
        }

        Ok((stats, elapsed))
    }

    /// Step 3: Execute operators on sample patterns
    fn execute_graph(
        &self,
        graph: &HologramGraph,
        input_shapes: &HashMap<String, Vec<i64>>,
    ) -> Result<(ExecutionResults, std::time::Duration)> {
        let start = Instant::now();

        if self.verbose {
            println!("\nâš™ï¸  Step 3: Executing operators...");
            if self.parallel {
                println!("   âœ“ Parallel processing enabled");
            }
        }

        // Create executor
        let executor = GraphExecutor::new()
            .with_memory_budget(self.memory_budget)
            .with_verbose(self.verbose)
            .with_parallel(self.parallel);

        let results = executor.execute(graph, input_shapes)?;

        let elapsed = start.elapsed();

        if self.verbose {
            println!("   âœ“ Executed {} operations", graph.petgraph().node_count());
            println!("   âœ“ Generated {} patterns", results.total_patterns);
            println!("   âœ“ Time: {:?}", elapsed);
        }

        Ok((results, elapsed))
    }

    /// Step 4: Serialize to .holo binary
    fn serialize_binary(
        &self,
        graph: &HologramGraph,
        results: &ExecutionResults,
        output_path: &Path,
    ) -> Result<(SerializerStats, std::time::Duration)> {
        let start = Instant::now();

        if self.verbose {
            println!("\nðŸ’¾ Step 4: Serializing to .holo...");
        }

        // Create serializer
        let serializer = HoloSerializer::new().with_verbose(self.verbose);

        let stats = serializer.serialize(graph, results, output_path)?;

        let elapsed = start.elapsed();

        if self.verbose {
            println!(
                "   âœ“ Hash tables: {:.2} MB",
                stats.hash_table_bytes as f64 / 1_000_000.0
            );
            println!(
                "   âœ“ Address space: {:.2} MB",
                stats.address_space_bytes as f64 / 1_000_000.0
            );
            println!(
                "   âœ“ Total: {:.2} MB",
                stats.total_bytes as f64 / 1_000_000.0
            );
            println!("   âœ“ Time: {:?}", elapsed);
        }

        Ok((stats, elapsed))
    }

    /// Auto-detect input shapes for common models
    fn auto_detect_input_shapes_map(
        &self,
        graph: &HologramGraph,
    ) -> Result<HashMap<String, Vec<i64>>> {
        let mut shapes = HashMap::new();

        // Extract actual shapes from ONNX ValueInfoProto metadata
        for input in graph.graph_inputs() {
            // Try to extract shape from ONNX type info
            let shape = if let Some(ref type_proto) = input.r#type {
                if let Some(ref value) = type_proto.value {
                    use crate::proto::type_proto::Value;
                    if let Value::TensorType(ref tensor_type) = value {
                        if let Some(ref shape_proto) = tensor_type.shape {
                            // Calculate actual dimensions from shape
                            let dims: Vec<i64> = shape_proto
                                .dim
                                .iter()
                                .map(|d| {
                                    // Handle both static dims and dynamic dims
                                    if let Some(ref dim_value) = d.value {
                                        use crate::proto::tensor_shape_proto::dimension::Value as DimValue;
                                        match dim_value {
                                            DimValue::DimValue(v) => *v,
                                            DimValue::DimParam(_) => {
                                                // Dynamic dimension - use default
                                                // For sequence dims, use 77 (CLIP default)
                                                // For batch dims, use 1
                                                if input.name.contains("input_ids") || input.name.contains("sequence") {
                                                    77
                                                } else {
                                                    1
                                                }
                                            }
                                        }
                                    } else {
                                        1 // Unknown dimension
                                    }
                                })
                                .collect();

                            if !dims.is_empty() {
                                dims
                            } else {
                                // Empty shape - use default
                                vec![1, 256]
                            }
                        } else {
                            // No shape info - use default
                            vec![1, 256]
                        }
                    } else {
                        // Not a tensor type - use default
                        vec![1, 256]
                    }
                } else {
                    // No value - use default
                    vec![1, 256]
                }
            } else {
                // No type info - use default
                vec![1, 256]
            };

            shapes.insert(input.name.clone(), shape);
        }

        Ok(shapes)
    }
}

impl Default for Compiler {
    fn default() -> Self {
        Self::new()
    }
}

/// Compilation statistics
#[derive(Debug, Clone)]
pub struct CompilationStats {
    /// Total operations in final graph
    pub total_operations: usize,

    /// Original operation count (before optimization)
    pub original_operations: usize,

    /// Optimized operation count (after fusion, DCE)
    pub optimized_operations: usize,

    /// Number of unique subgraphs detected
    pub unique_subgraphs: usize,

    /// Total patterns generated
    pub total_patterns: usize,

    /// Hash table size in bytes
    pub hash_table_size: usize,

    /// Address space size in bytes
    pub address_space_size: usize,

    /// Total compilation time
    pub compilation_time: std::time::Duration,
}

/// Optimization statistics (from optimizer.rs)
#[derive(Debug, Clone, Default)]
pub struct OptimizationStats {
    pub original_ops: usize,
    pub optimized_ops: usize,
    pub unique_subgraphs: usize,
    pub fused_operations: usize,
    pub eliminated_dead_ops: usize,
}

/// Execution results (from executor.rs)
#[derive(Debug, Clone)]
pub struct ExecutionResults {
    /// Total patterns generated
    pub total_patterns: usize,

    /// Hash tables for O(1) lookup (per operation)
    pub hash_tables: Vec<HashMap<u64, Vec<f32>>>,

    /// Operation metadata
    pub metadata: Vec<OperationMetadata>,
}

/// Operation metadata
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct OperationMetadata {
    pub op_type: String,
    pub input_shapes: Vec<Option<Vec<i64>>>,
    pub output_shapes: Vec<Vec<i64>>,
}

/// Serializer statistics (from serializer.rs)
#[derive(Debug, Clone)]
pub struct SerializerStats {
    pub hash_table_bytes: usize,
    pub address_space_bytes: usize,
    pub total_bytes: usize,
}
