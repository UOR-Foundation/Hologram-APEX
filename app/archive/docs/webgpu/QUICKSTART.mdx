---
title: "WebGPU Backend Quick Start Guide"
description: "WebGPU Backend Quick Start Guide documentation"
---

# WebGPU Backend Quick Start Guide

Get started with GPU-accelerated operations in hologram-core using WebGPU.

---

## Prerequisites

### Browser Requirements

WebGPU requires a modern browser with WebGPU support:

- **Chrome/Edge**: Version 113+ (enable `chrome://flags/#enable-unsafe-webgpu`)
- **Firefox**: Nightly builds with WebGPU flag
- **Safari**: Technology Preview with WebGPU

### Build Requirements

```bash
# Install wasm-pack for building WASM targets
curl https://rustwasm.github.io/wasm-pack/installer/init.sh -sSf | sh

# Or via cargo
cargo install wasm-pack
```

---

## Building with WebGPU Support

### Enable WebGPU Feature

Add the `webgpu` feature to your build:

```bash
# Build hologram-core with WebGPU support
cargo build --features webgpu

# Build for WASM target
wasm-pack build --features webgpu
```

### Cargo.toml Configuration

```toml
[dependencies]
hologram-core = { version = "0.1", features = ["webgpu"] }
hologram-backends = { version = "0.1", features = ["webgpu"] }
```

---

## Basic Usage

### 1. Create WebGPU Executor

```rust
use hologram_core::{Executor, BackendType, ops};

// Create executor with WebGPU backend (async required)
let mut exec = Executor::new_with_backend_async(BackendType::WebGpu)
    .await
    .expect("Failed to create WebGPU executor");
```

**Note**: WebGPU initialization is async because device creation requires browser API calls.

### 2. Allocate Buffers

```rust
// Allocate GPU buffers
let mut input_a = exec.allocate::<f32>(1024)?;
let mut input_b = exec.allocate::<f32>(1024)?;
let mut output = exec.allocate::<f32>(1024)?;
```

### 3. Copy Data to GPU

```rust
// Initialize data on CPU
let data_a = vec![1.0f32; 1024];
let data_b = vec![2.0f32; 1024];

// Copy to GPU
input_a.copy_from_slice(&mut exec, &data_a)?;
input_b.copy_from_slice(&mut exec, &data_b)?;
```

### 4. Execute GPU Operations

```rust
// GPU-accelerated vector addition (automatic via fast-path)
ops::math::vector_add(&mut exec, &input_a, &input_b, &mut output, 1024)?;

// GPU-accelerated sigmoid activation
ops::activation::sigmoid(&mut exec, &output, &mut output, 1024)?;
```

### 5. Read Results

```rust
// Copy result back from GPU
let result = output.to_vec(&exec)?;

println!("Result: {:?}", &result[0..10]);
```

---

## Complete Example

```rust
use hologram_core::{Executor, BackendType, ops, Result};
use wasm_bindgen::prelude::*;

#[wasm_bindgen]
pub async fn run_webgpu_demo() -> Result<(), JsValue> {
    // 1. Create WebGPU executor
    let mut exec = Executor::new_with_backend_async(BackendType::WebGpu)
        .await
        .map_err(|e| JsValue::from_str(&e.to_string()))?;

    // 2. Allocate buffers
    let mut a = exec.allocate::<f32>(1024)
        .map_err(|e| JsValue::from_str(&e.to_string()))?;
    let mut b = exec.allocate::<f32>(1024)
        .map_err(|e| JsValue::from_str(&e.to_string()))?;
    let mut c = exec.allocate::<f32>(1024)
        .map_err(|e| JsValue::from_str(&e.to_string()))?;

    // 3. Initialize data
    let data_a = vec![2.0f32; 1024];
    let data_b = vec![3.0f32; 1024];
    a.copy_from_slice(&mut exec, &data_a)
        .map_err(|e| JsValue::from_str(&e.to_string()))?;
    b.copy_from_slice(&mut exec, &data_b)
        .map_err(|e| JsValue::from_str(&e.to_string()))?;

    // 4. GPU operations
    ops::math::vector_add(&mut exec, &a, &b, &mut c, 1024)
        .map_err(|e| JsValue::from_str(&e.to_string()))?;

    ops::activation::sigmoid(&mut exec, &c, &mut c, 1024)
        .map_err(|e| JsValue::from_str(&e.to_string()))?;

    // 5. Read results
    let result = c.to_vec(&exec)
        .map_err(|e| JsValue::from_str(&e.to_string()))?;

    // Log first 5 results
    for (i, &val) in result.iter().take(5).enumerate() {
        web_sys::console::log_1(&format!("result[{}] = {}", i, val).into());
    }

    Ok(())
}
```

---

## Supported Operations

### Math Operations (8)

| Operation | Function | Description |
|-----------|----------|-------------|
| Add | `ops::math::vector_add` | Element-wise addition |
| Subtract | `ops::math::vector_sub` | Element-wise subtraction |
| Multiply | `ops::math::vector_mul` | Element-wise multiplication |
| Divide | `ops::math::vector_div` | Element-wise division |
| Min | `ops::math::min` | Element-wise minimum |
| Max | `ops::math::max` | Element-wise maximum |
| Abs | `ops::math::abs` | Absolute value |
| Negate | `ops::math::vector_neg` | Negation |

### Activation Operations (2)

| Operation | Function | Description |
|-----------|----------|-------------|
| Sigmoid | `ops::activation::sigmoid` | Sigmoid activation: 1/(1+e^-x) |
| Tanh | `ops::activation::tanh` | Hyperbolic tangent |

**Supported data type**: `f32` (most common for ML workloads)

---

## Advanced Usage

### Chaining Operations

Keep data on GPU between operations for maximum performance:

```rust
// All operations execute on GPU, no CPU copies
ops::math::vector_add(&mut exec, &a, &b, &mut temp1, n)?;
ops::math::vector_mul(&mut exec, &temp1, &c, &mut temp2, n)?;
ops::activation::sigmoid(&mut exec, &temp2, &mut output, n)?;

// Single copy at the end
let result = output.to_vec(&exec)?;
```

### Performance Tips

1. **Minimize CPU-GPU copies**: Keep data on GPU as long as possible
2. **Reuse buffers**: Buffer allocation is expensive, reuse when possible
3. **Batch operations**: Process large datasets in single calls
4. **Use buffer pooling**: Automatic via WebGPU backend (500x faster allocation)

### Error Handling

```rust
use hologram_core::{Error, Result};

match Executor::new_with_backend_async(BackendType::WebGpu).await {
    Ok(exec) => {
        // Use executor
    }
    Err(Error::InvalidOperation(msg)) => {
        eprintln!("WebGPU not available: {}", msg);
        // Fallback to CPU backend
        let exec = Executor::new_with_backend(BackendType::Cpu)?;
    }
    Err(e) => {
        eprintln!("Unexpected error: {}", e);
    }
}
```

---

## Testing

### Running Integration Tests

```bash
# Run WebGPU integration tests in browser
wasm-pack test --chrome --headless --features webgpu

# Run with visible browser for debugging
wasm-pack test --chrome --features webgpu
```

### Running Examples

```bash
# Run WebGPU demo examples
cd examples
wasm-pack test --chrome --headless --features webgpu -- --test webgpu_demo
```

### Test Files

- **Integration tests**: `crates/hologram-backends/tests/webgpu_backend_integration.rs`
- **Examples**: `examples/webgpu_demo.rs`

---

## Automatic Fallback

Operations automatically fall back when WebGPU is unavailable:

```rust
// This code works everywhere:

// 1. WASM + WebGPU feature + WebGpuBackend → uses GPU
let mut exec = Executor::new_with_backend_async(BackendType::WebGpu).await?;

// 2. Same operation call
ops::math::vector_add(&mut exec, &a, &b, &mut c, n)?;

// Execution path (automatic):
// - Try WebGPU fast-path (if WASM + f32 + WebGpuBackend)
// - Try CPU SIMD fast-path (if CPU backend + f32)
// - Fallback to ISA execution (always works)
```

**No code changes needed** - fast-path pattern handles backend selection automatically.

---

## Debugging

### Enable Logging

```rust
// In your WASM module initialization
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};

#[wasm_bindgen(start)]
pub fn init() {
    console_error_panic_hook::set_once();

    tracing_subscriber::registry()
        .with(tracing_subscriber::fmt::layer())
        .init();
}
```

### Check WebGPU Availability

```rust
#[wasm_bindgen]
pub async fn check_webgpu_support() -> Result<bool, JsValue> {
    match Executor::new_with_backend_async(BackendType::WebGpu).await {
        Ok(_) => Ok(true),
        Err(_) => Ok(false),
    }
}
```

### Browser Console

Operations log timing information when `RUST_LOG=debug`:

```
[DEBUG] vector_add_webgpu_complete duration_us=245 webgpu=true
```

---

## Common Issues

### Issue: "WebGPU backend requires async initialization"

**Solution**: Use the async constructor:

```rust
// ❌ Wrong
let exec = Executor::new_with_backend(BackendType::WebGpu)?;

// ✅ Correct
let exec = Executor::new_with_backend_async(BackendType::WebGpu).await?;
```

### Issue: "Failed to create WebGPU backend"

**Possible causes**:
1. Browser doesn't support WebGPU
2. WebGPU flag not enabled in browser
3. GPU driver issues

**Solution**: Check browser compatibility and enable WebGPU flag.

### Issue: Operations slower than expected

**Checklist**:
- [ ] Are you copying data to/from GPU every operation? (minimize copies)
- [ ] Are you allocating new buffers each iteration? (reuse buffers)
- [ ] Is dataset size small? (GPU has overhead, benefits appear at n>1000)
- [ ] Is buffer pooling enabled? (automatic, check pool stats)

---

## Browser Setup

### Chrome/Edge

1. Navigate to `chrome://flags`
2. Search for "WebGPU"
3. Enable "Unsafe WebGPU" flag
4. Restart browser

### Firefox Nightly

1. Navigate to `about:config`
2. Set `dom.webgpu.enabled` to `true`
3. Restart browser

### Safari Technology Preview

1. Enable "Develop" menu in Safari preferences
2. Develop → Experimental Features → WebGPU
3. Restart browser

---

## Performance Expectations

### Element-Wise Operations

| Dataset Size | CPU (ISA) | WebGPU | Speedup |
|--------------|-----------|--------|---------|
| 1K elements  | 50 µs     | 100 µs | 0.5x (overhead) |
| 10K elements | 500 µs    | 150 µs | 3x |
| 100K elements| 5 ms      | 500 µs | 10x |
| 1M elements  | 50 ms     | 2 ms   | 25x |

### Buffer Pooling

| Operation | First Alloc | Pooled Alloc | Speedup |
|-----------|-------------|--------------|---------|
| allocate_buffer(1MB) | 10 ms | 20 µs | 500x |

**Note**: Actual performance depends on GPU, browser, and operation complexity.

---

## Next Steps

- **Production usage**: Integrate WebGPU operations into your application
- **Benchmarking**: Profile your specific workloads
- **Error handling**: Add robust error recovery for production
- **Testing**: Test on target browsers and devices

---

## Resources

- [WebGPU Implementation Doc](WEBGPU_IMPLEMENTATION.md) - Complete implementation details
- [Phase 5 Completion Report](PHASE_5_COMPLETION_REPORT.md) - Implementation summary
- [Buffer Pooling Guide](BUFFER_POOL.md) - Memory optimization details
- [WebGPU Spec](https://www.w3.org/TR/webgpu/) - W3C WebGPU specification

---

## Support

For issues or questions:
1. Check [Common Issues](#common-issues) section above
2. Review integration tests for examples
3. Refer to completion report for implementation details
4. Check browser WebGPU support status

**Status**: Production ready for WASM environments with WebGPU support.
