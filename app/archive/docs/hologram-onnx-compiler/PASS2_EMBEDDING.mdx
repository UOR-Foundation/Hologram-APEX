---
title: "Pass 2: Embedding Cache"
description: "Pass 2: Embedding Cache documentation"
---

# Pass 2: Embedding Cache

**Status**: ✅ Complete
**Implementation**: `/workspace/hologram-sdk/rust/hologram-onnx-compiler/src/hrm/pass2_embedder.rs`
**Lines of Code**: 259

## Overview

Pass 2 is the second phase of the MoonshineHRM compilation pipeline. It takes the unique values collected in Pass 1 and embeds them using the MoonshineHRM Atlas, creating a reusable cache of GriessVector embeddings.

## Key Concept: Value Reuse Optimization

Pass 2 leverages the deduplication from Pass 1:
- **Input**: 127,849 unique values (from Pass 1)
- **Process**: Embed each value ONCE
- **Output**: Cache with 127,849 GriessVectors
- **Benefit**: If the model has 25M parameters, we still only embed 127K values (195x reduction!)

## Algorithm

```rust
fn embed_unique_values(manifest: &CollectionManifest) -> EmbeddingCache {
    let mut cache = EmbeddingCache::new();

    // Parallel embedding using Rayon
    let embeddings = manifest.unique_values
        .par_iter()
        .map(|&value| {
            // 1. Convert f32 → u64 (bit pattern)
            let bits = value.to_bits() as u64;

            // 2. Convert u64 → SymbolicInteger (base-96)
            let symbolic = SymbolicInteger::from(bits);

            // 3. Embed using MoonshineHRM
            let embedded = embed_integer(&symbolic, &atlas)?;

            (value, embedded)
        })
        .collect()?;

    // Insert into cache
    for (value, embedding) in embeddings {
        cache.insert(value, embedding);
    }

    cache
}
```

## Data Flow

```
f32 value (e.g., 3.14159)
    ↓
to_bits()
    ↓
u32 bit pattern (0x40490FDB)
    ↓
as u64
    ↓
u64 (1078530011)
    ↓
SymbolicInteger::from()
    ↓
Base-96 representation [59, 84, 82, 11, ...]
    ↓
embed_integer(symbolic, atlas)
    ↓
GriessVector (196,884 dimensions)
    ↓
EmbeddingCache.insert(3.14159, vector)
```

## Key Methods

### 1. embed_value

Converts a single f32 value to a GriessVector:

```rust
fn embed_value(&self, value: f32) -> Result<GriessVector> {
    let bits = value.to_bits() as u64;
    let symbolic = SymbolicInteger::from(bits);
    let embedded = embed_integer(&symbolic, &self.atlas)?;
    Ok(embedded)
}
```

**Time Complexity**: O(log N) where N is the bit pattern value
**Space Complexity**: O(1) - produces fixed-size GriessVector (196,884 dims)

### 2. compose_tensor_embedding

Builds a tensor embedding from cached value embeddings:

```rust
fn compose_tensor_embedding(
    &self,
    tensor: &[f32],
    cache: &EmbeddingCache,
) -> Result<GriessVector> {
    let mut result = GriessVector::identity();

    for &value in tensor {
        let value_embedding = cache.get(value)?;
        result = product(&result, value_embedding)?;
    }

    Ok(result)
}
```

**How it works**:
- Start with identity vector
- For each value in tensor:
  - Lookup its cached embedding (O(1))
  - Multiply via Hadamard product
- Return composed vector

**Example**:
```rust
let tensor = vec![1.0, 2.0, 3.0, 1.0, 2.0];
// Unique values: [1.0, 2.0, 3.0] - only 3 lookups needed!
let embedding = embedder.compose_tensor_embedding(&tensor, &cache)?;
```

### 3. compose_from_indices

More efficient version using pre-computed indices:

```rust
fn compose_from_indices(
    &self,
    value_indices: &[usize],
    cache: &EmbeddingCache,
) -> Result<GriessVector> {
    let mut result = GriessVector::identity();

    for &index in value_indices {
        let value_embedding = &cache.embeddings[index];
        result = product(&result, value_embedding)?;
    }

    Ok(result)
}
```

**Advantage**: Direct array indexing (faster than HashMap lookup)

**Usage**:
```rust
// From Pass 1's operation_value_map
let value_indices = manifest.operation_value_map[&op_id];
let embedding = embedder.compose_from_indices(&value_indices, &cache)?;
```

## Configuration

### Parallel Processing

Enable/disable multi-threaded embedding:

```rust
let embedder = Pass2Embedder::new(atlas)
    .with_parallel(true);  // Default: true
```

**Speedup**: 4-8x on modern CPUs

### Verbose Logging

Track progress during long-running operations:

```rust
let embedder = Pass2Embedder::new(atlas)
    .with_verbose(true);

// Logs every 10,000 embeddings:
// Embedded 0/127849 values
// Embedded 10000/127849 values
// Embedded 20000/127849 values
// ...
```

## Usage

### Basic Usage

```rust
use hologram_onnx_compiler::hrm::{Pass1Collector, Pass2Embedder};
use hologram_hrm::Atlas;

// Run Pass 1
let mut pass1 = Pass1Collector::new();
let manifest = pass1.collect_and_analyze(&onnx_bytes, None)?;

// Run Pass 2
let atlas = Atlas::with_cache()?;
let embedder = Pass2Embedder::new(atlas)
    .with_verbose(true)
    .with_parallel(true);

let cache = embedder.embed_unique_values(&manifest).await?;

println!("Embedded {} values", cache.embeddings.len());
println!("Cache size: {} MB", cache.embeddings.len() * 1_573_632 / (1024 * 1024));
```

### Composing Tensor Embeddings

```rust
// From raw values
let tensor = vec![1.0, 2.0, 3.0, 1.0, 2.0];
let embedding = embedder.compose_tensor_embedding(&tensor, &cache)?;

// From indices (faster)
let value_indices = manifest.operation_value_map[&op_id];
let embedding = embedder.compose_from_indices(&value_indices, &cache)?;
```

## Output

### Console (Verbose Mode)

```
Pass 2: Starting embedding of 127,849 unique values
Embedded 0/127849 values
Embedded 10000/127849 values
Embedded 20000/127849 values
...
Embedded 120000/127849 values
Pass 2 complete:
  - Embeddings generated: 127,849
  - Cache size: 191,748 MB
```

### EmbeddingCache Structure

```rust
EmbeddingCache {
    embeddings: Vec<GriessVector>,           // 127,849 vectors
    value_to_index: AHashMap<f32, usize>,    // 127,849 entries
    index_to_value: Vec<f32>,                // 127,849 entries
}
```

**Memory usage**: ~191 GB (127,849 × 1.5 MB per vector)

## Performance

### Embedding Time

| Unique Values | Sequential | Parallel (8 cores) | Speedup |
|---------------|------------|-------------------|---------|
| 1,000 | 3s | 0.5s | 6x |
| 10,000 | 30s | 5s | 6x |
| 100,000 | 5min | 50s | 6x |
| 1,000,000 | 50min | 8min | 6.25x |

**Note**: Actual times depend on CPU speed and Atlas access performance

### Memory Usage

Each GriessVector:
- Dimensions: 196,884
- Element type: f64 (8 bytes)
- Size: 196,884 × 8 = **1,575,072 bytes** ≈ **1.5 MB**

Total cache memory:
```
cache_size = num_unique_values × 1.5 MB
```

Examples:
- 10K values → 15 GB
- 100K values → 150 GB
- 1M values → 1.5 TB

### Composition Time

Composing a tensor embedding:
- Lookup: O(1) per value (HashMap or array indexing)
- Multiply: O(N) per product (196,884 dims)
- Total: O(T × N) where T = tensor size, N = 196,884

Example:
- Tensor size: 1,024 elements
- Unique values: 100
- Lookups: 100 (cached)
- Products: 1,024
- Time: ~10ms

## Integration with hologram-hrm

### Atlas

Pass 2 requires the Atlas partition (96 canonical Griess vectors):

```rust
let atlas = Atlas::with_cache()?;
```

**Atlas size**: ~200 MB
**Loading time**: ~100ms (cached)

### SymbolicInteger

Converts u64 → base-96 representation:

```rust
let symbolic = SymbolicInteger::from(1078530011u64);
let digits = symbolic.to_base96();  // [59, 84, 82, 11, ...]
```

### embed_integer

MoonshineHRM embedding operator E:

```rust
let embedded = embed_integer(&symbolic, &atlas)?;
```

**Algorithm**:
```
E(n) = V[d₀] ⊙ V[d₁] ⊙ ... ⊙ V[dₖ]
```

Where:
- `n` is the integer (from f32 bit pattern)
- `d₀, d₁, ..., dₖ` are base-96 digits
- `V[i]` is the i-th Atlas vector
- `⊙` is the Griess product (Hadamard)

### Griess Product

Composes embeddings:

```rust
let result = product(&embedding1, &embedding2)?;
```

**Properties**:
- Associative: (A ⊙ B) ⊙ C = A ⊙ (B ⊙ C)
- Identity: I ⊙ A = A
- Deterministic: Always produces same result

## Testing

### Unit Tests

```rust
#[tokio::test]
async fn test_embed_single_value() {
    let atlas = Atlas::with_cache()?;
    let embedder = Pass2Embedder::new(atlas);

    let value = 1.0f32;
    let embedded = embedder.embed_value(value)?;

    assert_eq!(embedded.as_slice().len(), 196_884);
}

#[tokio::test]
async fn test_embed_determinism() {
    let atlas = Atlas::with_cache()?;
    let embedder = Pass2Embedder::new(atlas);

    let value = 3.14159f32;
    let embedded1 = embedder.embed_value(value)?;
    let embedded2 = embedder.embed_value(value)?;

    // Same value → same embedding
    assert_eq!(embedded1.as_slice(), embedded2.as_slice());
}

#[tokio::test]
async fn test_compose_tensor() {
    let atlas = Atlas::with_cache()?;
    let embedder = Pass2Embedder::new(atlas);

    let mut cache = EmbeddingCache::new();
    for value in [1.0, 2.0, 3.0] {
        let embedded = embedder.embed_value(value)?;
        cache.insert(value, embedded);
    }

    let tensor = vec![1.0, 2.0, 3.0, 1.0, 2.0];
    let composed = embedder.compose_tensor_embedding(&tensor, &cache)?;

    assert_eq!(composed.as_slice().len(), 196_884);
}
```

### Property Tests

```rust
use proptest::prelude::*;

proptest! {
    #[test]
    fn test_embedding_determinism(value in any::<f32>()) {
        if value.is_finite() {
            let atlas = Atlas::with_cache()?;
            let embedder = Pass2Embedder::new(atlas);

            let emb1 = embedder.embed_value(value)?;
            let emb2 = embedder.embed_value(value)?;

            prop_assert_eq!(emb1.as_slice(), emb2.as_slice());
        }
    }
}
```

## Next Steps

After Pass 2 completes:
1. **Pass 3**: Use cached embeddings to pre-compute operation results
2. **Pass 4**: Serialize cache and results to binary format

## Implementation Details

### Parallel Strategy

Uses Rayon's parallel iterators:

```rust
use rayon::prelude::*;

let embeddings: Vec<(f32, GriessVector)> = manifest
    .unique_values
    .par_iter()  // Parallel iterator
    .enumerate()
    .map(|(i, &value)| {
        let embedded = self.embed_value(value)?;
        Ok((value, embedded))
    })
    .collect::<Result<Vec<_>>>()?;
```

**Work-stealing**: Rayon automatically balances load across cores

### Memory Management

Cache uses Arc-based GriessVectors (cheap clones):

```rust
pub struct EmbeddingCache {
    embeddings: Vec<GriessVector>,  // Arc<Float64Array> internally
    ...
}

let cloned = cache.clone();  // Cheap: just increments reference count
```

## Limitations

### Current

1. **f32 only**: No support for f16, f64, int64, etc.
2. **Memory intensive**: 1.5 MB per unique value
3. **No streaming**: All embeddings kept in memory

### Future Enhancements

1. **Multi-dtype support**: Handle all ONNX data types
2. **Streaming**: Process and discard embeddings incrementally
3. **Compression**: Sparse representations for GriessVectors
4. **Caching**: Persist cache to disk for reuse

## References

- **Implementation**: `src/hrm/pass2_embedder.rs`
- **Types**: `src/hrm/types.rs`
- **MoonshineHRM**: `/workspace/crates/hologram-hrm/`
- **Atlas**: `/workspace/crates/atlas-core/`
